{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ‚úçÔ∏è Homework 8: Prompt Engineering\n",
    "**MIS 769 - Big Data Analytics for Business | Spring 2026**\n",
    "\n",
    "**Points:** 20 | **Due:** Sunday, April 5, 2026 @ 11pm Pacific\n",
    "\n",
    "**Author:** Richard Young, Ph.D. | UNLV Lee Business School\n",
    "\n",
    "**Compute:** CPU (free tier)\n",
    "\n",
    "---\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "1. Core prompt engineering techniques\n",
    "2. Zero-shot, few-shot, and chain-of-thought prompting\n",
    "3. Evaluate prompt effectiveness systematically\n",
    "4. Optimize prompts for specific business tasks\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Setup and Zero-Shot Prompts (3 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers torch datasets -q\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "# Load a model for text generation\n",
    "generator = pipeline(\n",
    "    \"text2text-generation\",\n",
    "    model=\"google/flan-t5-base\",\n",
    "    max_new_tokens=100\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Model loaded (flan-t5-base)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt(text):\n",
    "    \"\"\"Send a prompt to the model and return the response.\"\"\"\n",
    "    response = generator(text)[0]['generated_text']\n",
    "    return response\n",
    "\n",
    "# Zero-shot examples\n",
    "print(\"üìù ZERO-SHOT PROMPTING\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Sentiment classification\n",
    "review = \"The product arrived late but works great.\"\n",
    "result = prompt(f\"Classify the sentiment of this review as positive, negative, or neutral: '{review}'\")\n",
    "print(f\"\\nTask: Sentiment Classification\")\n",
    "print(f\"Input: \\\"{review}\\\"\")\n",
    "print(f\"Output: {result}\")\n",
    "\n",
    "# Summarization\n",
    "text = \"The company reported quarterly earnings that exceeded analyst expectations by 15%. Revenue grew to $5.2 billion, driven by strong sales in the technology division.\"\n",
    "result = prompt(f\"Summarize this in one sentence: {text}\")\n",
    "print(f\"\\nTask: Summarization\")\n",
    "print(f\"Input: \\\"{text[:50]}...\\\"\")\n",
    "print(f\"Output: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Few-Shot Prompts (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Few-shot prompting for classification\n",
    "print(\"üìù FEW-SHOT PROMPTING\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "few_shot_prompt = \"\"\"Classify customer complaints into categories.\n",
    "\n",
    "Example 1:\n",
    "Complaint: \"My order never arrived\"\n",
    "Category: Shipping\n",
    "\n",
    "Example 2:\n",
    "Complaint: \"The product broke after one day\"\n",
    "Category: Quality\n",
    "\n",
    "Example 3:\n",
    "Complaint: \"I was charged twice\"\n",
    "Category: Billing\n",
    "\n",
    "Now classify:\n",
    "Complaint: \"The app keeps crashing when I try to checkout\"\n",
    "Category:\"\"\"\n",
    "\n",
    "result = prompt(few_shot_prompt)\n",
    "print(f\"Few-shot prompt with 3 examples\")\n",
    "print(f\"New complaint: \\\"The app keeps crashing when I try to checkout\\\"\")\n",
    "print(f\"Predicted category: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare zero-shot vs few-shot\n",
    "test_complaints = [\n",
    "    \"The color is different from the picture\",\n",
    "    \"Customer service was rude to me\",\n",
    "    \"My package was damaged when it arrived\"\n",
    "]\n",
    "\n",
    "print(\"üìä ZERO-SHOT vs FEW-SHOT COMPARISON\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for complaint in test_complaints:\n",
    "    # Zero-shot\n",
    "    zero_shot = prompt(f\"Classify this complaint into a category: '{complaint}'\")\n",
    "    \n",
    "    # Few-shot\n",
    "    few_shot = prompt(f\"\"\"{few_shot_prompt.replace('The app keeps crashing when I try to checkout', complaint)}\"\"\")\n",
    "    \n",
    "    print(f\"\\nComplaint: \\\"{complaint}\\\"\")\n",
    "    print(f\"  Zero-shot: {zero_shot}\")\n",
    "    print(f\"  Few-shot:  {few_shot}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Chain-of-Thought Prompting (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chain-of-thought for reasoning\n",
    "print(\"üìù CHAIN-OF-THOUGHT PROMPTING\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Without CoT\n",
    "problem = \"A store has 50 apples. They sell 23 and receive 15 more. How many apples?\"\n",
    "without_cot = prompt(problem)\n",
    "print(f\"\\nProblem: {problem}\")\n",
    "print(f\"Without CoT: {without_cot}\")\n",
    "\n",
    "# With CoT\n",
    "cot_prompt = f\"\"\"{problem}\n",
    "\n",
    "Let's think step by step:\n",
    "1. Start with 50 apples\n",
    "2. Sell 23: 50 - 23 = 27 apples\n",
    "3. Receive 15: 27 + 15 = 42 apples\n",
    "\n",
    "Final answer:\"\"\"\n",
    "\n",
    "with_cot = prompt(cot_prompt)\n",
    "print(f\"With CoT: {with_cot}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Business reasoning with CoT\n",
    "print(\"\\nüìä BUSINESS REASONING WITH COT\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "review = \"The product quality is amazing but shipping took forever and customer service was unhelpful.\"\n",
    "\n",
    "# Without CoT - simple classification\n",
    "without_cot = prompt(f\"Is this review positive, negative, or mixed? Review: '{review}'\")\n",
    "print(f\"\\nReview: \\\"{review}\\\"\")\n",
    "print(f\"Without CoT: {without_cot}\")\n",
    "\n",
    "# With CoT - detailed analysis\n",
    "cot_prompt = f\"\"\"Analyze this review step by step:\n",
    "\n",
    "Review: \"{review}\"\n",
    "\n",
    "Step 1: Identify positive aspects mentioned.\n",
    "Step 2: Identify negative aspects mentioned.\n",
    "Step 3: Determine overall sentiment based on balance.\n",
    "\n",
    "Analysis:\"\"\"\n",
    "\n",
    "with_cot = prompt(cot_prompt)\n",
    "print(f\"With CoT: {with_cot}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Prompt Optimization (4 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteratively improve a prompt\n",
    "print(\"üìä PROMPT OPTIMIZATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "test_review = \"Great battery life, but the screen is too dim and it overheats sometimes.\"\n",
    "\n",
    "# Version 1: Vague\n",
    "v1 = prompt(f\"List features: {test_review}\")\n",
    "print(f\"\\nV1 (Vague): 'List features'\")\n",
    "print(f\"   Result: {v1}\")\n",
    "\n",
    "# Version 2: More specific\n",
    "v2 = prompt(f\"Extract product features mentioned in this review: {test_review}\")\n",
    "print(f\"\\nV2 (Specific): 'Extract product features'\")\n",
    "print(f\"   Result: {v2}\")\n",
    "\n",
    "# Version 3: Structured output\n",
    "v3 = prompt(f\"\"\"Extract features from this review as a list:\n",
    "Review: {test_review}\n",
    "Features (positive and negative):\"\"\")\n",
    "print(f\"\\nV3 (Structured): 'Extract as list'\")\n",
    "print(f\"   Result: {v3}\")\n",
    "\n",
    "# Version 4: Categorized\n",
    "v4 = prompt(f\"\"\"Extract product features from this review.\n",
    "Separate into POSITIVE and NEGATIVE features.\n",
    "\n",
    "Review: {test_review}\n",
    "\n",
    "POSITIVE:\n",
    "NEGATIVE:\"\"\")\n",
    "print(f\"\\nV4 (Categorized): 'Separate positive/negative'\")\n",
    "print(f\"   Result: {v4}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Document your optimization journey\n",
    "optimization_log = [\n",
    "    {\"version\": \"V1\", \"prompt\": \"List features\", \"issue\": \"Too vague\"},\n",
    "    {\"version\": \"V2\", \"prompt\": \"Extract product features\", \"issue\": \"No structure\"},\n",
    "    {\"version\": \"V3\", \"prompt\": \"Extract as a list\", \"issue\": \"Mixed positive/negative\"},\n",
    "    {\"version\": \"V4\", \"prompt\": \"Separate positive/negative\", \"issue\": \"Best so far\"},\n",
    "]\n",
    "\n",
    "print(\"\\nüìù OPTIMIZATION LOG\")\n",
    "print(\"=\" * 60)\n",
    "for entry in optimization_log:\n",
    "    print(f\"{entry['version']}: {entry['prompt'][:30]}... ‚Üí {entry['issue']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Documentation (3 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test your best prompts on multiple examples\n",
    "test_reviews = [\n",
    "    \"Love the camera quality! Battery could be better though.\",\n",
    "    \"Fast shipping, product was exactly as described.\",\n",
    "    \"Terrible experience. Product broke immediately and no refund.\"\n",
    "]\n",
    "\n",
    "print(\"üìä FINAL PROMPT EVALUATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "best_prompt_template = \"\"\"Extract product features from this review.\n",
    "Separate into POSITIVE and NEGATIVE features.\n",
    "\n",
    "Review: {review}\n",
    "\n",
    "POSITIVE:\n",
    "NEGATIVE:\"\"\"\n",
    "\n",
    "for review in test_reviews:\n",
    "    result = prompt(best_prompt_template.format(review=review))\n",
    "    print(f\"\\nReview: \\\"{review[:50]}...\\\"\")\n",
    "    print(f\"Extracted: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Questions to Answer\n",
    "\n",
    "**Q1:** Which prompting technique worked best for your task? Why?\n",
    "\n",
    "*Your answer:*\n",
    "\n",
    "**Q2:** Show your prompt iteration history. What improved results most?\n",
    "\n",
    "*Your answer:*\n",
    "\n",
    "**Q3:** When did few-shot outperform zero-shot? When didn't it matter?\n",
    "\n",
    "*Your answer:*\n",
    "\n",
    "**Q4:** How would you A/B test prompts in a production system?\n",
    "\n",
    "*Your answer:*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Submission Checklist\n",
    "\n",
    "| Item | Points | Done? |\n",
    "|------|--------|-------|\n",
    "| Part 1: Zero-shot prompts | 3 | ‚òê |\n",
    "| Part 2: Few-shot prompts | 5 | ‚òê |\n",
    "| Part 3: Chain-of-thought | 5 | ‚òê |\n",
    "| Part 4: Prompt optimization | 4 | ‚òê |\n",
    "| Part 5: Documentation | 3 | ‚òê |\n",
    "| **Total** | **20** | |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
