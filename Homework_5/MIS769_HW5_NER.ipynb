{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üè∑Ô∏è Homework 5: Named Entity Recognition (NER)\n",
    "**MIS 769 - Big Data Analytics for Business | Spring 2026**\n",
    "\n",
    "**Points:** 20 | **Due:** Sunday, March 1, 2026 @ 11pm Pacific\n",
    "\n",
    "**Author:** Richard Young, Ph.D. | UNLV Lee Business School\n",
    "\n",
    "**Compute:** CPU (free tier)\n",
    "\n",
    "---\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "1. Named Entity Recognition (NER) concepts\n",
    "2. Use spaCy for entity extraction\n",
    "3. Extract business-relevant entities from text\n",
    "4. Analyze entity patterns\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Setup and Data Loading (3 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install spacy datasets pandas matplotlib seaborn -q\n",
    "!python -m spacy download en_core_web_sm -q\n",
    "\n",
    "import spacy\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "print(\"‚úÖ spaCy loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load dataset\n",
    "dataset = load_dataset(\"stanfordnlp/imdb\", split=\"train[:5000]\")\n",
    "df = dataset.to_pandas()\n",
    "\n",
    "print(f\"‚úÖ Loaded {len(df):,} reviews\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Understanding NER Entity Types (4 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo NER on sample text\n",
    "sample_text = \"\"\"\n",
    "Apple CEO Tim Cook announced the new iPhone 15 in San Francisco yesterday.\n",
    "The product costs $999 and will be available in the United States starting\n",
    "September 22, 2024. Amazon and Best Buy will also carry the device.\n",
    "\"\"\"\n",
    "\n",
    "doc = nlp(sample_text)\n",
    "\n",
    "print(\"üìä NAMED ENTITIES FOUND\")\n",
    "print(\"-\" * 60)\n",
    "for ent in doc.ents:\n",
    "    print(f\"{ent.text:20} | {ent.label_:10} | {spacy.explain(ent.label_)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Extract Entities from Reviews (6 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_entities(text):\n",
    "    \"\"\"Extract named entities from text.\"\"\"\n",
    "    doc = nlp(str(text)[:5000])  # Limit for speed\n",
    "    entities = {\n",
    "        'ORG': [],\n",
    "        'PRODUCT': [],\n",
    "        'GPE': [],\n",
    "        'PERSON': [],\n",
    "    }\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ in entities:\n",
    "            entities[ent.label_].append(ent.text)\n",
    "    return entities\n",
    "\n",
    "# Extract from all reviews\n",
    "print(\"Extracting entities (this takes 1-2 minutes)...\")\n",
    "\n",
    "all_orgs = []\n",
    "all_products = []\n",
    "all_locations = []\n",
    "all_persons = []\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    if idx % 500 == 0:\n",
    "        print(f\"   Processing {idx}/{len(df)}...\")\n",
    "    entities = extract_entities(row['text'])\n",
    "    all_orgs.extend(entities['ORG'])\n",
    "    all_products.extend(entities['PRODUCT'])\n",
    "    all_locations.extend(entities['GPE'])\n",
    "    all_persons.extend(entities['PERSON'])\n",
    "\n",
    "print(f\"\\n‚úÖ Extraction complete!\")\n",
    "print(f\"   ORG: {len(all_orgs):,}\")\n",
    "print(f\"   PRODUCT: {len(all_products):,}\")\n",
    "print(f\"   GPE: {len(all_locations):,}\")\n",
    "print(f\"   PERSON: {len(all_persons):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Analyze Entity Patterns (4 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most common entities\n",
    "org_counts = Counter(all_orgs).most_common(15)\n",
    "person_counts = Counter(all_persons).most_common(15)\n",
    "location_counts = Counter(all_locations).most_common(10)\n",
    "\n",
    "print(\"üìä TOP ORGANIZATIONS\")\n",
    "print(\"-\" * 40)\n",
    "for org, count in org_counts:\n",
    "    print(f\"{org:25} | {count}\")\n",
    "\n",
    "print(\"\\nüìä TOP PEOPLE\")\n",
    "print(\"-\" * 40)\n",
    "for person, count in person_counts:\n",
    "    print(f\"{person:25} | {count}\")\n",
    "\n",
    "print(\"\\nüìä TOP LOCATIONS\")\n",
    "print(\"-\" * 40)\n",
    "for loc, count in location_counts:\n",
    "    print(f\"{loc:25} | {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Visualization (3 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "\n",
    "# Organizations\n",
    "if org_counts:\n",
    "    orgs, counts = zip(*org_counts[:10])\n",
    "    axes[0].barh(orgs, counts, color='steelblue')\n",
    "    axes[0].set_title('Top 10 Organizations')\n",
    "    axes[0].invert_yaxis()\n",
    "\n",
    "# People\n",
    "if person_counts:\n",
    "    persons, counts = zip(*person_counts[:10])\n",
    "    axes[1].barh(persons, counts, color='coral')\n",
    "    axes[1].set_title('Top 10 People')\n",
    "    axes[1].invert_yaxis()\n",
    "\n",
    "# Locations\n",
    "if location_counts:\n",
    "    locs, counts = zip(*location_counts[:10])\n",
    "    axes[2].barh(locs, counts, color='seagreen')\n",
    "    axes[2].set_title('Top 10 Locations')\n",
    "    axes[2].invert_yaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('ner_analysis.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Questions to Answer\n",
    "\n",
    "**Q1:** Were the extracted entities accurate? What errors did you observe?\n",
    "\n",
    "*Your answer:*\n",
    "\n",
    "**Q2:** What business insights can you derive from entity mentions?\n",
    "\n",
    "*Your answer:*\n",
    "\n",
    "**Q3:** How could you improve NER for your specific domain?\n",
    "\n",
    "*Your answer:*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Submission Checklist\n",
    "\n",
    "| Item | Points | Done? |\n",
    "|------|--------|-------|\n",
    "| Part 1: Setup and data loaded | 3 | ‚òê |\n",
    "| Part 2: NER demo with explanations | 4 | ‚òê |\n",
    "| Part 3: Entity extraction from reviews | 6 | ‚òê |\n",
    "| Part 4: Analysis of patterns | 4 | ‚òê |\n",
    "| Part 5: Visualization | 3 | ‚òê |\n",
    "| **Total** | **20** | |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
