{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ‚úçÔ∏è Homework 8: Prompt Engineering\n",
    "**MIS 769 - Big Data Analytics for Business | Spring 2026**\n",
    "\n",
    "**Points:** 20 | **Due:** Sunday, April 5, 2026 @ 11pm Pacific\n",
    "\n",
    "**Author:** Richard Young, Ph.D. | UNLV Lee Business School\n",
    "\n",
    "**Compute:** CPU (free tier)\n",
    "\n",
    "---\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "1. Core prompt engineering techniques\n",
    "2. Zero-shot, few-shot, and chain-of-thought prompting\n",
    "3. Evaluate prompt effectiveness systematically\n",
    "4. Optimize prompts for specific business tasks\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## Chain-of-Thought Prompting\n\nA key prompt engineering technique is **Chain-of-Thought (CoT)**: asking the model to \"think step by step\" dramatically improves reasoning on complex problems. The simple phrase \"Let's think step by step\" can be the difference between wrong and right answers.\n\n![chain_of_thought.svg](data:image/svg+xml;base64,<?xml version="1.0" encoding="UTF-8"?>
<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 1344 768" width="1344" height="768">
  <defs>
    <linearGradient id="cotGrad" x1="0%" y1="0%" x2="0%" y2="100%">
      <stop offset="0%" style="stop-color:#ffd700;stop-opacity:1" />
      <stop offset="100%" style="stop-color:#cc9900;stop-opacity:1" />
    </linearGradient>

    <filter id="shadow" x="-20%" y="-20%" width="140%" height="140%">
      <feDropShadow dx="2" dy="3" stdDeviation="3" flood-opacity="0.3"/>
    </filter>

    <marker id="arrowGold" markerWidth="10" markerHeight="10" refX="9" refY="3" orient="auto">
      <path d="M0,0 L0,6 L9,3 z" fill="#ffd700"/>
    </marker>
  </defs>

  <!-- Background -->
  <rect width="1344" height="768" fill="#1a1a2e"/>

  <!-- Title -->
  <text x="672" y="45" font-family="Helvetica Neue, Arial, sans-serif" font-size="32" font-weight="bold" fill="white" text-anchor="middle">Chain-of-Thought Prompting</text>
  <text x="672" y="78" font-family="Helvetica Neue, Arial, sans-serif" font-size="18" fill="#888" text-anchor="middle">Eliciting step-by-step reasoning from LLMs</text>

  <!-- Standard Prompting -->
  <g transform="translate(70, 110)">
    <rect x="0" y="0" width="580" height="280" rx="12" fill="#252540" filter="url(#shadow)"/>
    <rect x="0" y="0" width="580" height="10" rx="5" fill="#ff6b6b"/>

    <text x="290" y="40" font-family="Helvetica Neue, Arial, sans-serif" font-size="16" font-weight="bold" fill="#ff6b6b" text-anchor="middle">Standard Prompting (Often Fails)</text>

    <g transform="translate(30, 60)" font-family="Monaco, monospace" font-size="10">
      <!-- Question -->
      <rect x="0" y="0" width="520" height="60" rx="4" fill="#1a1a2e"/>
      <text x="10" y="20" fill="#4a9eff">Q: Roger has 5 tennis balls. He buys 2 more</text>
      <text x="10" y="35" fill="#4a9eff">cans of 3. How many tennis balls does he</text>
      <text x="10" y="50" fill="#4a9eff">have now?</text>

      <!-- Direct answer attempt -->
      <line x1="260" y1="70" x2="260" y2="100" stroke="#ff6b6b" stroke-width="2" marker-end="url(#arrowGold)"/>

      <rect x="0" y="110" width="520" height="40" rx="4" fill="#ff6b6b" opacity="0.2" stroke="#ff6b6b" stroke-width="2"/>
      <text x="10" y="130" fill="#ff6b6b">A: 11 tennis balls.</text>
      <text x="10" y="145" fill="#888">(Wrong! Jumped to answer without reasoning)</text>

      <!-- Explanation -->
      <rect x="0" y="165" width="520" height="55" rx="4" fill="#1a1a2e"/>
      <text x="10" y="185" fill="#ffd700">Problem: LLM pattern-matches to similar problems</text>
      <text x="10" y="205" fill="#ddd">Without explicit reasoning, complex math fails</text>
    </g>
  </g>

  <!-- Chain-of-Thought -->
  <g transform="translate(690, 110)">
    <rect x="0" y="0" width="580" height="280" rx="12" fill="#252540" filter="url(#shadow)"/>
    <rect x="0" y="0" width="580" height="10" rx="5" fill="url(#cotGrad)"/>

    <text x="290" y="40" font-family="Helvetica Neue, Arial, sans-serif" font-size="16" font-weight="bold" fill="#ffd700" text-anchor="middle">Chain-of-Thought Prompting (Works!)</text>

    <g transform="translate(30, 60)" font-family="Monaco, monospace" font-size="10">
      <!-- Question with CoT prompt -->
      <rect x="0" y="0" width="520" height="60" rx="4" fill="#1a1a2e"/>
      <text x="10" y="20" fill="#4a9eff">Q: Roger has 5 tennis balls. He buys 2 more</text>
      <text x="10" y="35" fill="#4a9eff">cans of 3. How many tennis balls does he</text>
      <text x="10" y="50" fill="#4a9eff">have now? <tspan fill="#ffd700">Let's think step by step.</tspan></text>

      <!-- Step by step -->
      <line x1="260" y1="70" x2="260" y2="100" stroke="#ffd700" stroke-width="2" marker-end="url(#arrowGold)"/>

      <rect x="0" y="110" width="520" height="100" rx="4" fill="#4ecdc4" opacity="0.1" stroke="#4ecdc4" stroke-width="2"/>
      <text x="10" y="130" fill="#4ecdc4">A: Let me solve this step by step:</text>
      <text x="10" y="150" fill="#ddd">1. Roger starts with 5 tennis balls</text>
      <text x="10" y="170" fill="#ddd">2. He buys 2 cans × 3 balls = 6 new balls</text>
      <text x="10" y="190" fill="#ddd">3. Total: 5 + 6 = <tspan fill="#4ecdc4">11 tennis balls</tspan></text>
    </g>
  </g>

  <!-- CoT Variants -->
  <g transform="translate(70, 420)">
    <rect x="0" y="0" width="1200" height="180" rx="12" fill="#252540" filter="url(#shadow)"/>
    <rect x="0" y="0" width="1200" height="10" rx="5" fill="#4ecdc4"/>

    <text x="600" y="40" font-family="Helvetica Neue, Arial, sans-serif" font-size="16" font-weight="bold" fill="#4ecdc4" text-anchor="middle">Chain-of-Thought Variants</text>

    <g transform="translate(30, 60)" font-family="Monaco, monospace" font-size="10">
      <!-- Zero-shot CoT -->
      <rect x="0" y="0" width="270" height="100" rx="4" fill="#1a1a2e"/>
      <text x="135" y="20" fill="#ffd700" text-anchor="middle">Zero-shot CoT</text>
      <text x="135" y="45" fill="#ddd" text-anchor="middle">"Let's think step by step"</text>
      <text x="135" y="65" fill="#888" text-anchor="middle">No examples needed</text>
      <text x="135" y="85" fill="#4ecdc4" text-anchor="middle">Simple, effective</text>

      <!-- Few-shot CoT -->
      <rect x="290" y="0" width="270" height="100" rx="4" fill="#1a1a2e"/>
      <text x="425" y="20" fill="#ffd700" text-anchor="middle">Few-shot CoT</text>
      <text x="425" y="45" fill="#ddd" text-anchor="middle">Provide worked examples</text>
      <text x="425" y="65" fill="#888" text-anchor="middle">Model mimics reasoning</text>
      <text x="425" y="85" fill="#4ecdc4" text-anchor="middle">More reliable</text>

      <!-- Self-consistency -->
      <rect x="580" y="0" width="270" height="100" rx="4" fill="#1a1a2e"/>
      <text x="715" y="20" fill="#ffd700" text-anchor="middle">Self-Consistency</text>
      <text x="715" y="45" fill="#ddd" text-anchor="middle">Sample multiple chains</text>
      <text x="715" y="65" fill="#888" text-anchor="middle">Vote on final answer</text>
      <text x="715" y="85" fill="#4ecdc4" text-anchor="middle">More accurate</text>

      <!-- Tree of Thoughts -->
      <rect x="870" y="0" width="270" height="100" rx="4" fill="#1a1a2e"/>
      <text x="1005" y="20" fill="#ffd700" text-anchor="middle">Tree of Thoughts</text>
      <text x="1005" y="45" fill="#ddd" text-anchor="middle">Explore multiple paths</text>
      <text x="1005" y="65" fill="#888" text-anchor="middle">Backtrack if stuck</text>
      <text x="1005" y="85" fill="#4ecdc4" text-anchor="middle">Complex problems</text>
    </g>
  </g>

  <!-- Neuroscience Connection -->
  <g transform="translate(70, 630)">
    <rect x="0" y="0" width="1200" height="100" rx="12" fill="#252540" filter="url(#shadow)"/>
    <rect x="0" y="0" width="1200" height="10" rx="5" fill="#cc0000"/>

    <text x="100" y="40" font-family="Helvetica Neue, Arial, sans-serif" font-size="14" font-weight="bold" fill="#cc0000">Neuroscience: System 1 vs System 2</text>

    <g transform="translate(30, 55)" font-family="Monaco, monospace" font-size="10">
      <rect x="0" y="0" width="350" height="35" rx="4" fill="#1a1a2e"/>
      <text x="175" y="15" fill="#ff6b6b" text-anchor="middle">Standard Prompt = System 1</text>
      <text x="175" y="30" fill="#888" text-anchor="middle">Fast, intuitive, pattern matching</text>

      <rect x="370" y="0" width="350" height="35" rx="4" fill="#1a1a2e"/>
      <text x="545" y="15" fill="#4ecdc4" text-anchor="middle">Chain-of-Thought = System 2</text>
      <text x="545" y="30" fill="#888" text-anchor="middle">Slow, deliberate, step-by-step</text>

      <rect x="740" y="0" width="400" height="35" rx="4" fill="#1a1a2e"/>
      <text x="940" y="22" fill="#ffd700" text-anchor="middle">Externalizing reasoning improves problem-solving in both humans and LLMs</text>
    </g>
  </g>

</svg>
)\n\n---",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Setup and Zero-Shot Prompts (3 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers torch datasets -q\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "# Load a model for text generation\n",
    "generator = pipeline(\n",
    "    \"text2text-generation\",\n",
    "    model=\"google/flan-t5-base\",\n",
    "    max_new_tokens=100\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Model loaded (flan-t5-base)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt(text):\n",
    "    \"\"\"Send a prompt to the model and return the response.\"\"\"\n",
    "    response = generator(text)[0]['generated_text']\n",
    "    return response\n",
    "\n",
    "# Zero-shot examples\n",
    "print(\"üìù ZERO-SHOT PROMPTING\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Sentiment classification\n",
    "review = \"The product arrived late but works great.\"\n",
    "result = prompt(f\"Classify the sentiment of this review as positive, negative, or neutral: '{review}'\")\n",
    "print(f\"\\nTask: Sentiment Classification\")\n",
    "print(f\"Input: \\\"{review}\\\"\")\n",
    "print(f\"Output: {result}\")\n",
    "\n",
    "# Summarization\n",
    "text = \"The company reported quarterly earnings that exceeded analyst expectations by 15%. Revenue grew to $5.2 billion, driven by strong sales in the technology division.\"\n",
    "result = prompt(f\"Summarize this in one sentence: {text}\")\n",
    "print(f\"\\nTask: Summarization\")\n",
    "print(f\"Input: \\\"{text[:50]}...\\\"\")\n",
    "print(f\"Output: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Few-Shot Prompts (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Few-shot prompting for classification\n",
    "print(\"üìù FEW-SHOT PROMPTING\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "few_shot_prompt = \"\"\"Classify customer complaints into categories.\n",
    "\n",
    "Example 1:\n",
    "Complaint: \"My order never arrived\"\n",
    "Category: Shipping\n",
    "\n",
    "Example 2:\n",
    "Complaint: \"The product broke after one day\"\n",
    "Category: Quality\n",
    "\n",
    "Example 3:\n",
    "Complaint: \"I was charged twice\"\n",
    "Category: Billing\n",
    "\n",
    "Now classify:\n",
    "Complaint: \"The app keeps crashing when I try to checkout\"\n",
    "Category:\"\"\"\n",
    "\n",
    "result = prompt(few_shot_prompt)\n",
    "print(f\"Few-shot prompt with 3 examples\")\n",
    "print(f\"New complaint: \\\"The app keeps crashing when I try to checkout\\\"\")\n",
    "print(f\"Predicted category: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare zero-shot vs few-shot\n",
    "test_complaints = [\n",
    "    \"The color is different from the picture\",\n",
    "    \"Customer service was rude to me\",\n",
    "    \"My package was damaged when it arrived\"\n",
    "]\n",
    "\n",
    "print(\"üìä ZERO-SHOT vs FEW-SHOT COMPARISON\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for complaint in test_complaints:\n",
    "    # Zero-shot\n",
    "    zero_shot = prompt(f\"Classify this complaint into a category: '{complaint}'\")\n",
    "    \n",
    "    # Few-shot\n",
    "    few_shot = prompt(f\"\"\"{few_shot_prompt.replace('The app keeps crashing when I try to checkout', complaint)}\"\"\")\n",
    "    \n",
    "    print(f\"\\nComplaint: \\\"{complaint}\\\"\")\n",
    "    print(f\"  Zero-shot: {zero_shot}\")\n",
    "    print(f\"  Few-shot:  {few_shot}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Chain-of-Thought Prompting (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chain-of-thought for reasoning\n",
    "print(\"üìù CHAIN-OF-THOUGHT PROMPTING\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Without CoT\n",
    "problem = \"A store has 50 apples. They sell 23 and receive 15 more. How many apples?\"\n",
    "without_cot = prompt(problem)\n",
    "print(f\"\\nProblem: {problem}\")\n",
    "print(f\"Without CoT: {without_cot}\")\n",
    "\n",
    "# With CoT\n",
    "cot_prompt = f\"\"\"{problem}\n",
    "\n",
    "Let's think step by step:\n",
    "1. Start with 50 apples\n",
    "2. Sell 23: 50 - 23 = 27 apples\n",
    "3. Receive 15: 27 + 15 = 42 apples\n",
    "\n",
    "Final answer:\"\"\"\n",
    "\n",
    "with_cot = prompt(cot_prompt)\n",
    "print(f\"With CoT: {with_cot}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Business reasoning with CoT\n",
    "print(\"\\nüìä BUSINESS REASONING WITH COT\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "review = \"The product quality is amazing but shipping took forever and customer service was unhelpful.\"\n",
    "\n",
    "# Without CoT - simple classification\n",
    "without_cot = prompt(f\"Is this review positive, negative, or mixed? Review: '{review}'\")\n",
    "print(f\"\\nReview: \\\"{review}\\\"\")\n",
    "print(f\"Without CoT: {without_cot}\")\n",
    "\n",
    "# With CoT - detailed analysis\n",
    "cot_prompt = f\"\"\"Analyze this review step by step:\n",
    "\n",
    "Review: \"{review}\"\n",
    "\n",
    "Step 1: Identify positive aspects mentioned.\n",
    "Step 2: Identify negative aspects mentioned.\n",
    "Step 3: Determine overall sentiment based on balance.\n",
    "\n",
    "Analysis:\"\"\"\n",
    "\n",
    "with_cot = prompt(cot_prompt)\n",
    "print(f\"With CoT: {with_cot}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Prompt Optimization (4 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteratively improve a prompt\n",
    "print(\"üìä PROMPT OPTIMIZATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "test_review = \"Great battery life, but the screen is too dim and it overheats sometimes.\"\n",
    "\n",
    "# Version 1: Vague\n",
    "v1 = prompt(f\"List features: {test_review}\")\n",
    "print(f\"\\nV1 (Vague): 'List features'\")\n",
    "print(f\"   Result: {v1}\")\n",
    "\n",
    "# Version 2: More specific\n",
    "v2 = prompt(f\"Extract product features mentioned in this review: {test_review}\")\n",
    "print(f\"\\nV2 (Specific): 'Extract product features'\")\n",
    "print(f\"   Result: {v2}\")\n",
    "\n",
    "# Version 3: Structured output\n",
    "v3 = prompt(f\"\"\"Extract features from this review as a list:\n",
    "Review: {test_review}\n",
    "Features (positive and negative):\"\"\")\n",
    "print(f\"\\nV3 (Structured): 'Extract as list'\")\n",
    "print(f\"   Result: {v3}\")\n",
    "\n",
    "# Version 4: Categorized\n",
    "v4 = prompt(f\"\"\"Extract product features from this review.\n",
    "Separate into POSITIVE and NEGATIVE features.\n",
    "\n",
    "Review: {test_review}\n",
    "\n",
    "POSITIVE:\n",
    "NEGATIVE:\"\"\")\n",
    "print(f\"\\nV4 (Categorized): 'Separate positive/negative'\")\n",
    "print(f\"   Result: {v4}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Document your optimization journey\n",
    "optimization_log = [\n",
    "    {\"version\": \"V1\", \"prompt\": \"List features\", \"issue\": \"Too vague\"},\n",
    "    {\"version\": \"V2\", \"prompt\": \"Extract product features\", \"issue\": \"No structure\"},\n",
    "    {\"version\": \"V3\", \"prompt\": \"Extract as a list\", \"issue\": \"Mixed positive/negative\"},\n",
    "    {\"version\": \"V4\", \"prompt\": \"Separate positive/negative\", \"issue\": \"Best so far\"},\n",
    "]\n",
    "\n",
    "print(\"\\nüìù OPTIMIZATION LOG\")\n",
    "print(\"=\" * 60)\n",
    "for entry in optimization_log:\n",
    "    print(f\"{entry['version']}: {entry['prompt'][:30]}... ‚Üí {entry['issue']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Documentation (3 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test your best prompts on multiple examples\n",
    "test_reviews = [\n",
    "    \"Love the camera quality! Battery could be better though.\",\n",
    "    \"Fast shipping, product was exactly as described.\",\n",
    "    \"Terrible experience. Product broke immediately and no refund.\"\n",
    "]\n",
    "\n",
    "print(\"üìä FINAL PROMPT EVALUATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "best_prompt_template = \"\"\"Extract product features from this review.\n",
    "Separate into POSITIVE and NEGATIVE features.\n",
    "\n",
    "Review: {review}\n",
    "\n",
    "POSITIVE:\n",
    "NEGATIVE:\"\"\"\n",
    "\n",
    "for review in test_reviews:\n",
    "    result = prompt(best_prompt_template.format(review=review))\n",
    "    print(f\"\\nReview: \\\"{review[:50]}...\\\"\")\n",
    "    print(f\"Extracted: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Questions to Answer\n",
    "\n",
    "**Q1:** Which prompting technique worked best for your task? Why?\n",
    "\n",
    "*Your answer:*\n",
    "\n",
    "**Q2:** Show your prompt iteration history. What improved results most?\n",
    "\n",
    "*Your answer:*\n",
    "\n",
    "**Q3:** When did few-shot outperform zero-shot? When didn't it matter?\n",
    "\n",
    "*Your answer:*\n",
    "\n",
    "**Q4:** How would you A/B test prompts in a production system?\n",
    "\n",
    "*Your answer:*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Submission Checklist\n",
    "\n",
    "| Item | Points | Done? |\n",
    "|------|--------|-------|\n",
    "| Part 1: Zero-shot prompts | 3 | ‚òê |\n",
    "| Part 2: Few-shot prompts | 5 | ‚òê |\n",
    "| Part 3: Chain-of-thought | 5 | ‚òê |\n",
    "| Part 4: Prompt optimization | 4 | ‚òê |\n",
    "| Part 5: Documentation | 3 | ‚òê |\n",
    "| **Total** | **20** | |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}