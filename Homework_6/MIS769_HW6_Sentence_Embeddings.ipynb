{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üî§ Homework 6: Sentence Embeddings\n",
    "**MIS 769 - Big Data Analytics for Business | Spring 2026**\n",
    "\n",
    "**Points:** 20 | **Due:** Sunday, March 8, 2026 @ 11pm Pacific\n",
    "\n",
    "**Author:** Richard Young, Ph.D. | UNLV Lee Business School\n",
    "\n",
    "**Compute:** CPU (free tier) ‚Äî GPU recommended for faster encoding\n",
    "\n",
    "---\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "1. Difference between word and sentence embeddings\n",
    "2. Use Sentence Transformers to encode text semantically\n",
    "3. Compute semantic similarity between documents\n",
    "4. Build a simple semantic search system\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Setup and Model Loading (3 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sentence-transformers datasets pandas numpy scikit-learn -q\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "print(\"üìä MODEL LOADED\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Model: all-MiniLM-L6-v2\")\n",
    "print(f\"Embedding dimension: {model.get_sentence_embedding_dimension()}\")\n",
    "print(f\"Max sequence length: {model.max_seq_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load dataset\n",
    "dataset = load_dataset(\"stanfordnlp/imdb\", split=\"train[:2000]\")\n",
    "df = dataset.to_pandas()\n",
    "\n",
    "print(f\"‚úÖ Loaded {len(df):,} reviews\")\n",
    "print(f\"\\nSample review (first 200 chars):\")\n",
    "print(df['text'].iloc[0][:200] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Text Encoding (4 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode single sentences\n",
    "sentences = [\n",
    "    \"This movie was absolutely fantastic!\",\n",
    "    \"I loved this film, it was great!\",\n",
    "    \"The movie was terrible and boring.\",\n",
    "    \"The bank is by the river.\",\n",
    "    \"I need to visit the bank for a loan.\"\n",
    "]\n",
    "\n",
    "embeddings = model.encode(sentences)\n",
    "\n",
    "print(\"üìä SENTENCE EMBEDDINGS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Number of sentences: {len(sentences)}\")\n",
    "print(f\"Embedding shape: {embeddings.shape}\")\n",
    "print(f\"\\nFirst embedding (first 10 values):\")\n",
    "print(embeddings[0][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode corpus (batch processing)\n",
    "print(\"Encoding reviews (this may take 1-2 minutes)...\")\n",
    "\n",
    "# Truncate reviews to avoid memory issues\n",
    "texts = [text[:512] for text in df['text'].tolist()]\n",
    "corpus_embeddings = model.encode(texts, show_progress_bar=True)\n",
    "\n",
    "print(f\"\\n‚úÖ Encoded {len(corpus_embeddings):,} reviews\")\n",
    "print(f\"Corpus embeddings shape: {corpus_embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Similarity Computation (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute similarity between sentence pairs\n",
    "print(\"üîç SEMANTIC SIMILARITY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "pairs = [\n",
    "    (0, 1),  # Similar sentiment, different words\n",
    "    (0, 2),  # Opposite sentiment\n",
    "    (3, 4),  # Different meanings of \"bank\"\n",
    "]\n",
    "\n",
    "for i, j in pairs:\n",
    "    sim = cosine_similarity([embeddings[i]], [embeddings[j]])[0][0]\n",
    "    print(f\"\\nSentence A: \\\"{sentences[i]}\\\"\")\n",
    "    print(f\"Sentence B: \\\"{sentences[j]}\\\"\")\n",
    "    print(f\"Similarity: {sim:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a similarity matrix\n",
    "similarity_matrix = cosine_similarity(embeddings)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(similarity_matrix, \n",
    "            xticklabels=[s[:30]+\"...\" for s in sentences],\n",
    "            yticklabels=[s[:30]+\"...\" for s in sentences],\n",
    "            annot=True, fmt=\".2f\", cmap=\"YlOrRd\")\n",
    "plt.title(\"Sentence Similarity Matrix\")\n",
    "plt.tight_layout()\n",
    "plt.savefig('similarity_matrix.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Semantic Search (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def semantic_search(query, corpus_embeddings, corpus_texts, top_k=5):\n",
    "    \"\"\"Find most similar documents to a query.\"\"\"\n",
    "    query_embedding = model.encode([query])\n",
    "    similarities = cosine_similarity(query_embedding, corpus_embeddings)[0]\n",
    "    top_indices = np.argsort(similarities)[::-1][:top_k]\n",
    "    \n",
    "    results = []\n",
    "    for idx in top_indices:\n",
    "        results.append({\n",
    "            'score': similarities[idx],\n",
    "            'text': corpus_texts[idx][:200] + \"...\"\n",
    "        })\n",
    "    return results\n",
    "\n",
    "# Test semantic search\n",
    "query = \"movies with surprising plot twists\"\n",
    "\n",
    "print(\"üîé SEMANTIC SEARCH RESULTS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Query: \\\"{query}\\\"\\n\")\n",
    "\n",
    "results = semantic_search(query, corpus_embeddings, texts)\n",
    "\n",
    "print(\"Top 5 Results:\")\n",
    "for i, r in enumerate(results, 1):\n",
    "    print(f\"\\n{i}. [Score: {r['score']:.2f}]\")\n",
    "    print(f\"   {r['text']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try more queries\n",
    "queries = [\n",
    "    \"heartwarming family movies\",\n",
    "    \"scary horror films\",\n",
    "    \"romantic comedy with happy ending\"\n",
    "]\n",
    "\n",
    "for query in queries:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Query: \\\"{query}\\\"\")\n",
    "    print(\"-\" * 60)\n",
    "    results = semantic_search(query, corpus_embeddings, texts, top_k=3)\n",
    "    for i, r in enumerate(results, 1):\n",
    "        print(f\"{i}. [{r['score']:.2f}] {r['text'][:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Analysis (3 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare semantic search vs keyword search\n",
    "query = \"films I didn't enjoy\"\n",
    "\n",
    "print(\"üìä SEMANTIC vs KEYWORD SEARCH\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Query: \\\"{query}\\\"\\n\")\n",
    "\n",
    "# Semantic search\n",
    "print(\"SEMANTIC SEARCH (embedding-based):\")\n",
    "semantic_results = semantic_search(query, corpus_embeddings, texts, top_k=3)\n",
    "for i, r in enumerate(semantic_results, 1):\n",
    "    print(f\"  {i}. [{r['score']:.2f}] {r['text'][:80]}...\")\n",
    "\n",
    "# Simple keyword search\n",
    "print(\"\\nKEYWORD SEARCH (exact match):\")\n",
    "keyword_results = [t[:80] for t in texts if 'enjoy' in t.lower()][:3]\n",
    "if keyword_results:\n",
    "    for i, r in enumerate(keyword_results, 1):\n",
    "        print(f\"  {i}. {r}...\")\n",
    "else:\n",
    "    print(\"  No exact matches found!\")\n",
    "\n",
    "print(\"\\nüí° Notice: Semantic search understands meaning, not just keywords!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Questions to Answer\n",
    "\n",
    "**Q1:** What makes two sentences similar according to the model?\n",
    "\n",
    "*Your answer:*\n",
    "\n",
    "**Q2:** Find an example where semantic search works better than keyword search.\n",
    "\n",
    "*Your answer:*\n",
    "\n",
    "**Q3:** Find an example where the model fails. Why might this happen?\n",
    "\n",
    "*Your answer:*\n",
    "\n",
    "**Q4:** How would you use this in a business application?\n",
    "\n",
    "*Your answer:*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Submission Checklist\n",
    "\n",
    "| Item | Points | Done? |\n",
    "|------|--------|-------|\n",
    "| Part 1: Model loading | 3 | ‚òê |\n",
    "| Part 2: Text encoding | 4 | ‚òê |\n",
    "| Part 3: Similarity computation | 5 | ‚òê |\n",
    "| Part 4: Semantic search | 5 | ‚òê |\n",
    "| Part 5: Analysis | 3 | ‚òê |\n",
    "| **Total** | **20** | |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
