{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \ud83d\ude80 Homework 9: Text Generation & HuggingFace Spaces\n",
    "**MIS 769 - Big Data Analytics for Business | Spring 2026**\n",
    "\n",
    "**Points:** 20 | **Due:** See WebCampus for deadline\n",
    "\n",
    "**Author:** Richard Young, Ph.D. | UNLV Lee Business School\n",
    "\n",
    "**Compute:** GPU recommended \u2014 Spaces deployment is free\n",
    "\n",
    "---\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "1. Use HuggingFace Transformers for text generation\n",
    "2. Understand generation parameters (temperature, top-k, top-p)\n",
    "3. Build an interactive demo with Gradio\n",
    "4. Deploy your application to HuggingFace Spaces\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## How GPT-2 Works: The Attention Mechanism\n",
    "\n",
    "GPT-2 is built on the **Transformer architecture**, which uses **self-attention** to process text. Instead of reading words sequentially like older models (RNNs), attention allows the model to look at all words simultaneously and decide which ones are most relevant for predicting the next word.\n",
    "\n",
    "![deployment_pipeline.svg](data:image/svg+xml;base64,<?xml version="1.0" encoding="UTF-8"?>
<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 1000 400" width="1000" height="400">
  <defs>
    <linearGradient id="colabGrad" x1="0%" y1="0%" x2="0%" y2="100%">
      <stop offset="0%" style="stop-color:#f9ab00;stop-opacity:1" />
      <stop offset="100%" style="stop-color:#e37400;stop-opacity:1" />
    </linearGradient>
    <linearGradient id="gradioGrad" x1="0%" y1="0%" x2="0%" y2="100%">
      <stop offset="0%" style="stop-color:#ff6b6b;stop-opacity:1" />
      <stop offset="100%" style="stop-color:#ee5a5a;stop-opacity:1" />
    </linearGradient>
    <linearGradient id="hfGrad" x1="0%" y1="0%" x2="0%" y2="100%">
      <stop offset="0%" style="stop-color:#ffcc00;stop-opacity:1" />
      <stop offset="100%" style="stop-color:#ff9500;stop-opacity:1" />
    </linearGradient>
    <linearGradient id="publicGrad" x1="0%" y1="0%" x2="0%" y2="100%">
      <stop offset="0%" style="stop-color:#4ecdc4;stop-opacity:1" />
      <stop offset="100%" style="stop-color:#26a69a;stop-opacity:1" />
    </linearGradient>

    <filter id="shadow" x="-20%" y="-20%" width="140%" height="140%">
      <feDropShadow dx="2" dy="3" stdDeviation="3" flood-opacity="0.2"/>
    </filter>

    <marker id="arrow" markerWidth="10" markerHeight="7" refX="9" refY="3.5" orient="auto">
      <polygon points="0 0, 10 3.5, 0 7" fill="#666"/>
    </marker>
  </defs>

  <!-- Background -->
  <rect width="1000" height="400" fill="#1a1a2e"/>

  <!-- Title -->
  <text x="500" y="45" font-family="SF Pro Display, -apple-system, sans-serif" font-size="28" font-weight="bold" fill="white" text-anchor="middle">From Notebook to Production</text>
  <text x="500" y="75" font-family="SF Pro Display, -apple-system, sans-serif" font-size="16" fill="#888" text-anchor="middle">The HuggingFace Spaces Deployment Pipeline</text>

  <!-- Step 1: Local Development -->
  <g transform="translate(80, 140)">
    <rect width="160" height="120" rx="12" fill="#252540" filter="url(#shadow)"/>
    <rect width="160" height="8" rx="4" fill="url(#colabGrad)"/>
    <text x="80" y="45" font-family="SF Pro Display, -apple-system, sans-serif" font-size="14" font-weight="bold" fill="white" text-anchor="middle">Local Development</text>
    <text x="80" y="70" font-family="SF Pro Display, -apple-system, sans-serif" font-size="24" text-anchor="middle">📓</text>
    <text x="80" y="100" font-family="SF Mono, monospace" font-size="12" fill="#f9ab00" text-anchor="middle">Google Colab</text>
  </g>

  <!-- Arrow 1 -->
  <line x1="250" y1="200" x2="310" y2="200" stroke="#666" stroke-width="3" marker-end="url(#arrow)"/>

  <!-- Step 2: Gradio Demo -->
  <g transform="translate(320, 140)">
    <rect width="160" height="120" rx="12" fill="#252540" filter="url(#shadow)"/>
    <rect width="160" height="8" rx="4" fill="url(#gradioGrad)"/>
    <text x="80" y="45" font-family="SF Pro Display, -apple-system, sans-serif" font-size="14" font-weight="bold" fill="white" text-anchor="middle">Gradio Demo</text>
    <text x="80" y="70" font-family="SF Pro Display, -apple-system, sans-serif" font-size="24" text-anchor="middle">🎨</text>
    <text x="80" y="100" font-family="SF Mono, monospace" font-size="12" fill="#ff6b6b" text-anchor="middle">app.py</text>
  </g>

  <!-- Arrow 2 -->
  <line x1="490" y1="200" x2="550" y2="200" stroke="#666" stroke-width="3" marker-end="url(#arrow)"/>

  <!-- Step 3: HuggingFace Spaces -->
  <g transform="translate(560, 140)">
    <rect width="160" height="120" rx="12" fill="#252540" filter="url(#shadow)"/>
    <rect width="160" height="8" rx="4" fill="url(#hfGrad)"/>
    <text x="80" y="45" font-family="SF Pro Display, -apple-system, sans-serif" font-size="14" font-weight="bold" fill="white" text-anchor="middle">HuggingFace Spaces</text>
    <text x="80" y="70" font-family="SF Pro Display, -apple-system, sans-serif" font-size="24" text-anchor="middle">🤗</text>
    <text x="80" y="100" font-family="SF Mono, monospace" font-size="12" fill="#ffcc00" text-anchor="middle">git push</text>
  </g>

  <!-- Arrow 3 -->
  <line x1="730" y1="200" x2="790" y2="200" stroke="#666" stroke-width="3" marker-end="url(#arrow)"/>

  <!-- Step 4: Public URL -->
  <g transform="translate(800, 140)">
    <rect width="140" height="120" rx="12" fill="#252540" filter="url(#shadow)"/>
    <rect width="140" height="8" rx="4" fill="url(#publicGrad)"/>
    <text x="70" y="45" font-family="SF Pro Display, -apple-system, sans-serif" font-size="14" font-weight="bold" fill="white" text-anchor="middle">Public URL</text>
    <text x="70" y="70" font-family="SF Pro Display, -apple-system, sans-serif" font-size="24" text-anchor="middle">🌐</text>
    <text x="70" y="100" font-family="SF Mono, monospace" font-size="12" fill="#4ecdc4" text-anchor="middle">Share!</text>
  </g>

  <!-- Bottom descriptions -->
  <g transform="translate(0, 310)">
    <text x="160" y="0" font-family="SF Pro Display, -apple-system, sans-serif" font-size="11" fill="#888" text-anchor="middle">Experiment with</text>
    <text x="160" y="16" font-family="SF Pro Display, -apple-system, sans-serif" font-size="11" fill="#888" text-anchor="middle">models &amp; parameters</text>

    <text x="400" y="0" font-family="SF Pro Display, -apple-system, sans-serif" font-size="11" fill="#888" text-anchor="middle">Build interactive</text>
    <text x="400" y="16" font-family="SF Pro Display, -apple-system, sans-serif" font-size="11" fill="#888" text-anchor="middle">UI for your model</text>

    <text x="640" y="0" font-family="SF Pro Display, -apple-system, sans-serif" font-size="11" fill="#888" text-anchor="middle">Deploy with</text>
    <text x="640" y="16" font-family="SF Pro Display, -apple-system, sans-serif" font-size="11" fill="#888" text-anchor="middle">one command</text>

    <text x="870" y="0" font-family="SF Pro Display, -apple-system, sans-serif" font-size="11" fill="#888" text-anchor="middle">Anyone can</text>
    <text x="870" y="16" font-family="SF Pro Display, -apple-system, sans-serif" font-size="11" fill="#888" text-anchor="middle">use your app!</text>
  </g>

  <!-- Step numbers -->
  <g font-family="SF Pro Display, -apple-system, sans-serif" font-size="12" font-weight="bold">
    <circle cx="160" cy="280" r="12" fill="#f9ab00"/>
    <text x="160" y="284" fill="#1a1a2e" text-anchor="middle">1</text>

    <circle cx="400" cy="280" r="12" fill="#ff6b6b"/>
    <text x="400" y="284" fill="#1a1a2e" text-anchor="middle">2</text>

    <circle cx="640" cy="280" r="12" fill="#ffcc00"/>
    <text x="640" y="284" fill="#1a1a2e" text-anchor="middle">3</text>

    <circle cx="870" cy="280" r="12" fill="#4ecdc4"/>
    <text x="870" y="284" fill="#1a1a2e" text-anchor="middle">4</text>
  </g>

</svg>
)\n",
    "\n",
    "**Key concepts in the diagram above:**\n",
    "- **Query (Q)**: What the model is currently trying to predict\n",
    "- **Key (K)**: What information each token provides for matching\n",
    "- **Value (V)**: The actual content to retrieve when there's a match\n",
    "- **Multi-Head Attention**: Running multiple attention computations in parallel to capture different relationships\n",
    "\n",
    "---"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Text Generation (4 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers torch gradio -q\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "# Load GPT-2 (small, works on CPU)\n",
    "generator = pipeline(\"text-generation\", model=\"gpt2\")\n",
    "\n",
    "print(\"\u2705 GPT-2 model loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic text generation\n",
    "prompt = \"The future of artificial intelligence\"\n",
    "\n",
    "output = generator(\n",
    "    prompt,\n",
    "    max_new_tokens=50,\n",
    "    do_sample=True,\n",
    "    pad_token_id=50256  # GPT-2 fix\n",
    ")\n",
    "\n",
    "print(\"\ud83d\udcdd TEXT GENERATION\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Prompt: \\\"{prompt}\\\"\")\n",
    "print(f\"\\nGenerated:\")\n",
    "print(output[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Parameter Exploration (4 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temperature comparison\n",
    "print(\"\ud83d\udcca TEMPERATURE COMPARISON\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "prompt = \"Once upon a time\"\n",
    "temperatures = [0.3, 0.7, 1.2]\n",
    "\n",
    "for temp in temperatures:\n",
    "    output = generator(\n",
    "        prompt,\n",
    "        max_new_tokens=30,\n",
    "        temperature=temp,\n",
    "        do_sample=True,\n",
    "        pad_token_id=50256\n",
    "    )\n",
    "    generated = output[0]['generated_text'][len(prompt):]\n",
    "    print(f\"\\nTemperature {temp}:\")\n",
    "    print(f\"  {generated[:80]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top-k and Top-p comparison\n",
    "print(\"\ud83d\udcca TOP-K AND TOP-P COMPARISON\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "configs = [\n",
    "    {\"top_k\": 10, \"top_p\": 1.0, \"name\": \"top_k=10\"},\n",
    "    {\"top_k\": 50, \"top_p\": 1.0, \"name\": \"top_k=50\"},\n",
    "    {\"top_k\": 0, \"top_p\": 0.9, \"name\": \"top_p=0.9\"},\n",
    "    {\"top_k\": 0, \"top_p\": 0.5, \"name\": \"top_p=0.5\"},\n",
    "]\n",
    "\n",
    "for cfg in configs:\n",
    "    output = generator(\n",
    "        prompt,\n",
    "        max_new_tokens=30,\n",
    "        top_k=cfg[\"top_k\"] if cfg[\"top_k\"] > 0 else None,\n",
    "        top_p=cfg[\"top_p\"],\n",
    "        do_sample=True,\n",
    "        pad_token_id=50256\n",
    "    )\n",
    "    generated = output[0]['generated_text'][len(prompt):]\n",
    "    print(f\"\\n{cfg['name']}:\")\n",
    "    print(f\"  {generated[:80]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a summary table\n",
    "print(\"\\n\ud83d\udcca PARAMETER SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\"\"\n",
    "| Parameter   | Effect                          | Typical Values |\n",
    "|-------------|--------------------------------|----------------|\n",
    "| temperature | Higher = more random           | 0.3-1.0        |\n",
    "| top_k       | Limits token choices           | 20-100         |\n",
    "| top_p       | Nucleus sampling threshold     | 0.8-0.95       |\n",
    "| max_tokens  | Maximum output length          | 50-500         |\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Gradio Interface (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def generate_text(prompt, temperature, max_length):\n",
    "    \"\"\"Generate text with specified parameters.\"\"\"\n",
    "    if not prompt:\n",
    "        return \"Please enter a prompt.\"\n",
    "    \n",
    "    result = generator(\n",
    "        prompt,\n",
    "        max_new_tokens=int(max_length),\n",
    "        temperature=temperature,\n",
    "        do_sample=True,\n",
    "        pad_token_id=50256\n",
    "    )\n",
    "    return result[0]['generated_text']\n",
    "\n",
    "# Create Gradio interface\n",
    "demo = gr.Interface(\n",
    "    fn=generate_text,\n",
    "    inputs=[\n",
    "        gr.Textbox(label=\"Prompt\", placeholder=\"Enter your prompt here...\", lines=2),\n",
    "        gr.Slider(0.1, 1.5, value=0.7, step=0.1, label=\"Temperature\"),\n",
    "        gr.Slider(20, 200, value=50, step=10, label=\"Max New Tokens\")\n",
    "    ],\n",
    "    outputs=gr.Textbox(label=\"Generated Text\", lines=5),\n",
    "    title=\"\ud83d\ude80 Text Generator\",\n",
    "    description=\"Generate creative text using GPT-2. Adjust temperature for creativity.\",\n",
    "    examples=[\n",
    "        [\"The future of technology is\", 0.7, 50],\n",
    "        [\"Once upon a time in a magical forest\", 0.9, 100],\n",
    "        [\"Dear customer, thank you for\", 0.5, 50]\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"\ud83c\udfa8 GRADIO INTERFACE CREATED\")\n",
    "print(\"=\" * 60)\n",
    "print(\"Run demo.launch() to start the interface\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launch the demo (in Colab, this creates a public URL)\n",
    "demo.launch(share=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: HuggingFace Spaces Deployment (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the app.py file for Spaces\n",
    "app_code = '''\n",
    "import gradio as gr\n",
    "from transformers import pipeline\n",
    "\n",
    "# Load model\n",
    "generator = pipeline(\"text-generation\", model=\"gpt2\")\n",
    "\n",
    "def generate_text(prompt, temperature, max_length):\n",
    "    if not prompt:\n",
    "        return \"Please enter a prompt.\"\n",
    "    \n",
    "    result = generator(\n",
    "        prompt,\n",
    "        max_new_tokens=int(max_length),\n",
    "        temperature=temperature,\n",
    "        do_sample=True,\n",
    "        pad_token_id=50256\n",
    "    )\n",
    "    return result[0]['generated_text']\n",
    "\n",
    "demo = gr.Interface(\n",
    "    fn=generate_text,\n",
    "    inputs=[\n",
    "        gr.Textbox(label=\"Prompt\", placeholder=\"Enter your prompt...\"),\n",
    "        gr.Slider(0.1, 1.5, value=0.7, label=\"Temperature\"),\n",
    "        gr.Slider(20, 200, value=50, label=\"Max Tokens\")\n",
    "    ],\n",
    "    outputs=gr.Textbox(label=\"Generated Text\"),\n",
    "    title=\"Text Generator\",\n",
    "    description=\"Generate text with GPT-2\"\n",
    ")\n",
    "\n",
    "demo.launch()\n",
    "'''\n",
    "\n",
    "print(\"\ud83d\udcc4 APP.PY FOR HUGGINGFACE SPACES\")\n",
    "print(\"=\" * 60)\n",
    "print(app_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate requirements.txt\n",
    "requirements = \"\"\"transformers\n",
    "gradio\n",
    "torch\n",
    "\"\"\"\n",
    "\n",
    "print(\"\ud83d\udcc4 REQUIREMENTS.TXT\")\n",
    "print(\"=\" * 60)\n",
    "print(requirements)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deployment Steps\n",
    "\n",
    "1. Go to [huggingface.co/spaces](https://huggingface.co/spaces)\n",
    "2. Click \"Create new Space\"\n",
    "3. Choose a name (e.g., `text-generator`)\n",
    "4. Select **Gradio** as the SDK\n",
    "5. Upload `app.py` and `requirements.txt`\n",
    "6. Wait for the build to complete\n",
    "7. **Copy your Space URL and paste it below!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Record your Space URL\n",
    "space_url = \"https://huggingface.co/spaces/YOUR_USERNAME/YOUR_SPACE_NAME\"\n",
    "\n",
    "print(\"\ud83d\ude80 YOUR HUGGINGFACE SPACE\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"URL: {space_url}\")\n",
    "print(\"\\n\u26a0\ufe0f Replace with your actual Space URL before submitting!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Documentation (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test various generation scenarios\n",
    "test_prompts = [\n",
    "    \"Write a professional email starting with: Dear hiring manager,\",\n",
    "    \"Create a product description for: A smart water bottle that\",\n",
    "    \"Generate a tweet about: The benefits of remote work\"\n",
    "]\n",
    "\n",
    "print(\"\ud83d\udcca GENERATION SHOWCASE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for prompt in test_prompts:\n",
    "    output = generator(\n",
    "        prompt,\n",
    "        max_new_tokens=50,\n",
    "        temperature=0.7,\n",
    "        do_sample=True,\n",
    "        pad_token_id=50256\n",
    "    )\n",
    "    print(f\"\\nPrompt: {prompt[:50]}...\")\n",
    "    print(f\"Output: {output[0]['generated_text'][len(prompt):][:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Questions to Answer\n",
    "\n",
    "**Q1:** How do temperature and top-p affect output creativity?\n",
    "\n",
    "*Your answer:*\n",
    "\n",
    "**Q2:** What trade-offs did you make for Spaces deployment?\n",
    "\n",
    "*Your answer:*\n",
    "\n",
    "**Q3:** What would you add to make this production-ready?\n",
    "\n",
    "*Your answer:*\n",
    "\n",
    "**Q4:** Your HuggingFace Spaces URL:\n",
    "\n",
    "*Your URL:*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Submission Checklist\n",
    "\n",
    "| Item | Points | Done? |\n",
    "|------|--------|-------|\n",
    "| Part 1: Text generation | 4 | \u2610 |\n",
    "| Part 2: Parameter exploration | 4 | \u2610 |\n",
    "| Part 3: Gradio interface | 5 | \u2610 |\n",
    "| Part 4: Spaces deployment | 5 | \u2610 |\n",
    "| Part 5: Documentation | 2 | \u2610 |\n",
    "| **Total** | **20** | |\n",
    "\n",
    "**Don't forget to include your HuggingFace Spaces URL!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}